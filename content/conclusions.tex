\section{Conclusions}\label{sec:conclusions}
We have experimented with multiple agent architectures, including Distance and Simple
networks, as well as types of agents such as Q-learning, A2C, and DDPG\@.
We additionally developed and tested special training techniques including Controls
Policy Trainer and Reward Prioritized Memory.

We discovered all of these algorithms seem to struggle to adapt to Waterworld, but
A2C appears to perform best.
As previously shown, imitation learning can benefit agents learning Waterworld and
may be a more viable option.
However, we also were able to show there may be potential in using CPT, and encourage
additional research into how CPT can be used to enhance the DDPG and other training
algorithms.
